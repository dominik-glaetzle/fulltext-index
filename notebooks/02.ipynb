{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dominik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/dominik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/dominik/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/dominik/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "sys.path.append(\"../src\")\n",
    "from InvertedIndex import InvertedIndex\n",
    "from query_parser import load_queries_from_csv\n",
    "from BooleanRetrieval import BooleanRetrieval\n",
    "from analyzer import get_preprocessing_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exerice 1 & 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load / create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing index.\n"
     ]
    }
   ],
   "source": [
    "index = InvertedIndex()\n",
    "\n",
    "if not os.path.exists(\"../data/index.json\"):\n",
    "    with open(\"../data/cranfield-data-list.json\", \"r\", encoding=\"utf-8\") as data:\n",
    "        documents = json.load(data)\n",
    "\n",
    "    for doc in documents:\n",
    "        doc_id = doc[\"id\"]\n",
    "        doc_title = doc[\"title\"]\n",
    "        doc_author = doc[\"author\"]\n",
    "        doc_text = doc[\"body\"]\n",
    "\n",
    "        full_text = f\"{doc_title} {doc_text} {doc_author}\"\n",
    "        index.add_doc(doc_id, full_text)\n",
    "\n",
    "    index.write_to_disk()\n",
    "    print(\"Created new index.\")\n",
    "else:\n",
    "    index.load_from_disk()\n",
    "    print(f\"Loaded existing index.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load queries + print similarity measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 1: what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft.\n",
      "query tokens (11):  ['similar', 'law', 'must', 'obey', 'construct', 'aeroelast', 'model', 'heat', 'high', 'speed', 'aircraft']\n",
      " - doc-id:  576 (score: 0.45)\n",
      " - doc-id:  12 (score: 0.36)\n",
      " - doc-id:  51 (score: 0.36)\n"
     ]
    }
   ],
   "source": [
    "retrieval = BooleanRetrieval(index)\n",
    "queries = load_queries_from_csv()\n",
    "\n",
    "# print similarity measure sim(q, d) \n",
    "for i, q in enumerate(queries[:1]):\n",
    "    print(f\"\\nQuery {i+1}: {q}\")\n",
    "    results = retrieval.search(q)\n",
    "    for doc_id, score in results[:3]:\n",
    "        print(f\" - doc-id:  {doc_id} (score: {score:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>option</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>original</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>original</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>original</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>original</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>original</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>original</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>original</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id                                    option  count\n",
       "0        1                                  original    149\n",
       "1        1                    only-removed-stopwords     83\n",
       "2        1                removed-stopwords+stemming     83\n",
       "3        1  removed-stopwords+stemming+lemmatization     83\n",
       "4        2                                  original    204\n",
       "5        2                    only-removed-stopwords    121\n",
       "6        2                removed-stopwords+stemming    121\n",
       "7        2  removed-stopwords+stemming+lemmatization    121\n",
       "8        3                                  original     38\n",
       "9        3                    only-removed-stopwords     26\n",
       "10       3                removed-stopwords+stemming     26\n",
       "11       3  removed-stopwords+stemming+lemmatization     26\n",
       "12       4                                  original     90\n",
       "13       4                    only-removed-stopwords     55\n",
       "14       4                removed-stopwords+stemming     55\n",
       "15       4  removed-stopwords+stemming+lemmatization     55\n",
       "16       5                                  original     72\n",
       "17       5                    only-removed-stopwords     49\n",
       "18       5                removed-stopwords+stemming     49\n",
       "19       5  removed-stopwords+stemming+lemmatization     49\n",
       "20       6                                  original    112\n",
       "21       6                    only-removed-stopwords     61\n",
       "22       6                removed-stopwords+stemming     61\n",
       "23       6  removed-stopwords+stemming+lemmatization     61\n",
       "24       7                                  original    234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"../data/cranfield-data-list.json\", \"r\", encoding=\"utf-8\") as data:\n",
    "    documents = json.load(data)\n",
    "\n",
    "rows = []\n",
    "for doc in documents:\n",
    "    doc_id = doc[\"id\"]\n",
    "    full_text = f\"{doc['title']} {doc['body']} {doc['author']}\"\n",
    "    stats = get_preprocessing_stats(full_text)\n",
    "    for version, count in stats.items():\n",
    "        rows.append({\"doc_id\": doc_id, \"option\": version, \"count\": count})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "display(df.head(25))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-SWtUIMP9-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
