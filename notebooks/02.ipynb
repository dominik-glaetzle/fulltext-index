{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dominik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/dominik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/dominik/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/dominik/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "sys.path.append(\"../src\")\n",
    "from InvertedIndex import InvertedIndex\n",
    "from query_parser import load_queries_from_csv\n",
    "from BooleanRetrieval import BooleanRetrieval\n",
    "from analyzer import get_preprocessing_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)\n",
    "typically represented using a hash map where:\n",
    "\n",
    "- the key is a term from the document\n",
    "- the value is a list (postings list) of a document IDs that contain that word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing index.\n"
     ]
    }
   ],
   "source": [
    "index = InvertedIndex()\n",
    "\n",
    "if not os.path.exists(\"../data/index.json\"):\n",
    "    with open(\"../data/cranfield-data-list.json\", \"r\", encoding=\"utf-8\") as data:\n",
    "        documents = json.load(data)\n",
    "\n",
    "    for doc in documents:\n",
    "        doc_id = doc[\"id\"]\n",
    "        doc_title = doc[\"title\"]\n",
    "        doc_author = doc[\"author\"]\n",
    "        doc_text = doc[\"body\"]\n",
    "\n",
    "        full_text = f\"{doc_title} {doc_text} {doc_author}\"\n",
    "        index.add_doc(doc_id, full_text)\n",
    "\n",
    "    index.write_to_disk()\n",
    "    print(\"Created new index.\")\n",
    "else:\n",
    "    index.load_from_disk()\n",
    "    print(f\"Loaded existing index.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query 1: what similarity laws must be obeyed when constructing aeroelastic models of heated high speed aircraft.\n",
      "query tokens (11):  ['similar', 'law', 'must', 'obey', 'construct', 'aeroelast', 'model', 'heat', 'high', 'speed', 'aircraft']\n",
      " - doc-id:  576 (score: 0.45)\n",
      " - doc-id:  12 (score: 0.36)\n",
      " - doc-id:  51 (score: 0.36)\n",
      "\n",
      "Query 2: what are the structural and aeroelastic problems associated with flight of high speed aircraft.\n",
      "query tokens (8):  ['structur', 'aeroelast', 'problem', 'associ', 'flight', 'high', 'speed', 'aircraft']\n",
      " - doc-id:  12 (score: 0.50)\n",
      " - doc-id:  1089 (score: 0.50)\n",
      " - doc-id:  82 (score: 0.50)\n",
      "\n",
      "Query 3: can a criterion be developed to show empirically the validity of flow solutions for chemically reacting gas mixtures based on the simplifying assumption of instantaneous local chemical equilibrium.\n",
      "query tokens (18):  ['criterion', 'develop', 'show', 'empir', 'valid', 'flow', 'solut', 'chemic', 'react', 'ga', 'mixtur', 'base', 'simplifi', 'assumpt', 'instantan', 'local', 'chemic', 'equilibrium']\n",
      " - doc-id:  58 (score: 0.17)\n",
      " - doc-id:  146 (score: 0.17)\n",
      " - doc-id:  165 (score: 0.17)\n",
      "\n",
      "Query 4: is it possible to relate the available pressure distributions for an ogive forebody at zero angle of attack to the lower surface pressures of an equivalent ogive forebody at angle of attack.\n",
      "query tokens (18):  ['possibl', 'relat', 'avail', 'pressur', 'distribut', 'ogiv', 'forebodi', 'zero', 'angl', 'attack', 'lower', 'surfac', 'pressur', 'equival', 'ogiv', 'forebodi', 'angl', 'attack']\n",
      " - doc-id:  122 (score: 0.17)\n",
      " - doc-id:  225 (score: 0.17)\n",
      " - doc-id:  469 (score: 0.17)\n",
      "\n",
      "Query 5: what methods -dash exact or approximate -dash are presently available for predicting body pressures at angle of attack.\n",
      "query tokens (12):  ['method', 'dash', 'exact', 'approxim', 'dash', 'present', 'avail', 'predict', 'bodi', 'pressur', 'angl', 'attack']\n",
      " - doc-id:  70 (score: 0.25)\n",
      " - doc-id:  122 (score: 0.25)\n",
      " - doc-id:  124 (score: 0.25)\n",
      "\n",
      "Query 6: papers on internal /slip flow/ heat transfer studies.\n",
      "query tokens (7):  ['paper', 'intern', 'slip', 'flow', 'heat', 'transfer', 'studi']\n",
      " - doc-id:  21 (score: 0.57)\n",
      " - doc-id:  22 (score: 0.57)\n",
      " - doc-id:  45 (score: 0.57)\n",
      "\n",
      "Query 7: are real-gas transport properties for air available over a wide range of enthalpies and densities.\n",
      "query tokens (9):  ['realga', 'transport', 'properti', 'air', 'avail', 'wide', 'rang', 'enthalpi', 'densiti']\n",
      " - doc-id:  524 (score: 0.22)\n",
      " - doc-id:  110 (score: 0.22)\n",
      " - doc-id:  630 (score: 0.22)\n",
      "\n",
      "Query 8: is it possible to find an analytical, similar solution of the strong blast wave problem in the newtonian approximation.\n",
      "query tokens (11):  ['possibl', 'find', 'analyt', 'similar', 'solut', 'strong', 'blast', 'wave', 'problem', 'newtonian', 'approxim']\n",
      " - doc-id:  495 (score: 0.45)\n",
      " - doc-id:  72 (score: 0.36)\n",
      " - doc-id:  262 (score: 0.36)\n",
      "\n",
      "Query 9: how can the aerodynamic performance of channel flow ground effect machines be calculated.\n",
      "query tokens (8):  ['aerodynam', 'perform', 'channel', 'flow', 'ground', 'effect', 'machin', 'calcul']\n",
      " - doc-id:  417 (score: 0.38)\n",
      " - doc-id:  624 (score: 0.38)\n",
      " - doc-id:  792 (score: 0.38)\n",
      "\n",
      "Query 10: what is the basic mechanism of the transonic aileron buzz.\n",
      "query tokens (5):  ['basic', 'mechan', 'transon', 'aileron', 'buzz']\n",
      " - doc-id:  520 (score: 0.40)\n",
      " - doc-id:  496 (score: 0.40)\n",
      " - doc-id:  643 (score: 0.20)\n",
      "\n",
      "Query 11: papers on shock-sound wave interaction.\n",
      "query tokens (4):  ['paper', 'shocksound', 'wave', 'interact']\n",
      " - doc-id:  2 (score: 0.50)\n",
      " - doc-id:  170 (score: 0.50)\n",
      " - doc-id:  1198 (score: 0.50)\n",
      "\n",
      "Query 12: material properties of photoelastic materials.\n",
      "query tokens (4):  ['materi', 'properti', 'photoelast', 'materi']\n",
      "\n",
      "Query 13: can the three-dimensional problem of a transverse potential flow about a body of revolution be reduced to a two-dimensional problem.\n",
      "query tokens (10):  ['threedimension', 'problem', 'transvers', 'potenti', 'flow', 'bodi', 'revolut', 'reduc', 'twodimension', 'problem']\n",
      " - doc-id:  1 (score: 0.20)\n",
      " - doc-id:  2 (score: 0.20)\n",
      " - doc-id:  4 (score: 0.20)\n",
      "\n",
      "Query 14: can the transverse potential flow about a body of revolution be calculated efficiently by an electronic computer.\n",
      "query tokens (9):  ['transvers', 'potenti', 'flow', 'bodi', 'revolut', 'calcul', 'effici', 'electron', 'comput']\n",
      " - doc-id:  85 (score: 0.22)\n",
      " - doc-id:  259 (score: 0.22)\n",
      " - doc-id:  296 (score: 0.22)\n",
      "\n",
      "Query 15: does there exist a good basic treatment of the dynamics of re-entry combining consideration of realistic effects with relative simplicity of results.\n",
      "query tokens (13):  ['exist', 'good', 'basic', 'treatment', 'dynam', 'reentri', 'combin', 'consider', 'realist', 'effect', 'rel', 'simplic', 'result']\n",
      " - doc-id:  44 (score: 0.31)\n",
      " - doc-id:  94 (score: 0.23)\n",
      " - doc-id:  1248 (score: 0.23)\n",
      "\n",
      "Query 16: why does the compressibility transformation fail to correlate the high speed data for helium and air.\n",
      "query tokens (9):  ['compress', 'transform', 'fail', 'correl', 'high', 'speed', 'data', 'helium', 'air']\n",
      " - doc-id:  686 (score: 0.44)\n",
      " - doc-id:  24 (score: 0.33)\n",
      " - doc-id:  33 (score: 0.33)\n",
      "\n",
      "Query 17: has anyone formally determined the influence of joule heating, produced by the induced current, in magnetohydrodynamic free convection flows under general conditions.\n",
      "query tokens (15):  ['anyon', 'formal', 'determin', 'influenc', 'joul', 'heat', 'produc', 'induc', 'current', 'magnetohydrodynam', 'free', 'convect', 'flow', 'gener', 'condit']\n",
      " - doc-id:  22 (score: 0.20)\n",
      " - doc-id:  44 (score: 0.20)\n",
      " - doc-id:  45 (score: 0.20)\n",
      "\n",
      "Query 18: did anyone else discover that the turbulent skin friction is not over sensitive to the nature of the variation of the viscosity with temperature.\n",
      "query tokens (11):  ['anyon', 'el', 'discov', 'turbul', 'skin', 'friction', 'sensit', 'natur', 'variat', 'viscos', 'temperatur']\n",
      " - doc-id:  513 (score: 0.18)\n",
      " - doc-id:  1282 (score: 0.18)\n",
      " - doc-id:  4 (score: 0.18)\n",
      "\n",
      "Query 19: what are the factors which influence the time required to invert large structural matrices.\n",
      "query tokens (8):  ['factor', 'influenc', 'time', 'requir', 'invert', 'larg', 'structur', 'matric']\n",
      " - doc-id:  1034 (score: 0.25)\n",
      " - doc-id:  606 (score: 0.25)\n",
      " - doc-id:  280 (score: 0.25)\n",
      "\n",
      "Query 20: how is the design of ring or part ring wings by linear theory affected by thickness.\n",
      "query tokens (9):  ['design', 'ring', 'part', 'ring', 'wing', 'linear', 'theori', 'affect', 'thick']\n",
      " - doc-id:  42 (score: 0.33)\n",
      " - doc-id:  247 (score: 0.33)\n",
      " - doc-id:  1380 (score: 0.33)\n"
     ]
    }
   ],
   "source": [
    "retrieval = BooleanRetrieval(index)\n",
    "queries = load_queries_from_csv()\n",
    "\n",
    "# print similarity measure sim(q, d) \n",
    "for i, q in enumerate(queries[:20]):\n",
    "    print(f\"\\nQuery {i+1}: {q}\")\n",
    "    results = retrieval.search(q)\n",
    "    for doc_id, score in results[:3]:\n",
    "        print(f\" - doc-id:  {doc_id} (score: {score:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>option</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>original</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>original</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>original</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>original</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>original</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>original</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>only-removed-stopwords</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>removed-stopwords+stemming</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>removed-stopwords+stemming+lemmatization</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7</td>\n",
       "      <td>original</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id                                    option  count\n",
       "0        1                                  original    149\n",
       "1        1                    only-removed-stopwords     83\n",
       "2        1                removed-stopwords+stemming     83\n",
       "3        1  removed-stopwords+stemming+lemmatization     83\n",
       "4        2                                  original    204\n",
       "5        2                    only-removed-stopwords    121\n",
       "6        2                removed-stopwords+stemming    121\n",
       "7        2  removed-stopwords+stemming+lemmatization    121\n",
       "8        3                                  original     38\n",
       "9        3                    only-removed-stopwords     26\n",
       "10       3                removed-stopwords+stemming     26\n",
       "11       3  removed-stopwords+stemming+lemmatization     26\n",
       "12       4                                  original     90\n",
       "13       4                    only-removed-stopwords     55\n",
       "14       4                removed-stopwords+stemming     55\n",
       "15       4  removed-stopwords+stemming+lemmatization     55\n",
       "16       5                                  original     72\n",
       "17       5                    only-removed-stopwords     49\n",
       "18       5                removed-stopwords+stemming     49\n",
       "19       5  removed-stopwords+stemming+lemmatization     49\n",
       "20       6                                  original    112\n",
       "21       6                    only-removed-stopwords     61\n",
       "22       6                removed-stopwords+stemming     61\n",
       "23       6  removed-stopwords+stemming+lemmatization     61\n",
       "24       7                                  original    234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"../data/cranfield-data-list.json\", \"r\", encoding=\"utf-8\") as data:\n",
    "    documents = json.load(data)\n",
    "\n",
    "rows = []\n",
    "for doc in documents:\n",
    "    doc_id = doc[\"id\"]\n",
    "    full_text = f\"{doc['title']} {doc['body']} {doc['author']}\"\n",
    "    stats = get_preprocessing_stats(full_text)\n",
    "    for version, count in stats.items():\n",
    "        rows.append({\"doc_id\": doc_id, \"option\": version, \"count\": count})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "display(df.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-SWtUIMP9-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
